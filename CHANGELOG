project log:
- todo: add `share_id`, `time` in features

2019-04-12
- add `tool` folder for deploy

2019-04-05
- use `LinearClassifier` to train successfully

2019-03-20
- refactor: extractor is only responsible for extracting every kind of features as a data service. In every different algorithm, I use `DataFormatter` to present the schema.

2019-02-24
- [feature-extractor] upload awesome.db to COS
- [pre-process] download awesome.db from COS and export to feature.csv automatically

2019-02-07
- add feature dynamically when parse .csv file
- use different data definition for feature in DB and training stage. Because some of the features are generated dynamically

***
release `0.1`
a version can fetch some simple data and do the preprocess transform

2019-01-30:
- make table columns ordered
- add more ror metrics in DB.
- uniform the feature `price`, like close_price
- using Tensorflow Transform to do the preprocessing

2019-01-15ï¼š
- add new feature 10 days RoR
- use DataFrame to store each feature and merge them together into sqlite

2019-01-07:
- use `run.sh` to launch the pod
- logging to stderr and temp.log both

2019-01-04
- the feature extractor can extract the close price for all shares.
- dockerize the extractor and run it in k8s
- upload the result db to cos

2018-12-23
- create FEATURE table by feature_definition automatically.
