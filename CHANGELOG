project log:
2019-05-31:
- upload the exported models to cos

2019-05-16:
- add checkpoint for training

2019-05-14:
- use more features to do a test
- add more command parameters: `train_steps`, `download_feature_db`, `do_preprocessing`
- freeze `prebuild_v1`

2019-05-02:
- use 2 ways to implement the feature sdk. includes `sqlite` and `csv`
- reverse 4 digits for all float type in python

2019-04-23
- extract sample features for 10 years
- dockerize the training process

2019-04-12
- add `tool` folder for deploy

2019-04-05
- use `LinearClassifier` to train successfully

2019-03-20
- refactor: extractor is only responsible for extracting every kind of features as a data service. In every different algorithm, I use `DataFormatter` to present the schema.

2019-02-24
- [feature-extractor] upload awesome.db to COS
- [pre-process] download awesome.db from COS and export to feature.csv automatically

2019-02-07
- add feature dynamically when parse .csv file
- use different data definition for feature in DB and training stage. Because some of the features are generated dynamically

***
release `0.1`
a version can fetch some simple data and do the preprocess transform

2019-01-30:
- make table columns ordered
- add more ror metrics in DB.
- uniform the feature `price`, like close_price
- using Tensorflow Transform to do the preprocessing

2019-01-15ï¼š
- add new feature 10 days RoR
- use DataFrame to store each feature and merge them together into sqlite

2019-01-07:
- use `run_xxx.sh` to launch the pod
- logging to stderr and temp.log both

2019-01-04
- the feature extractor can extract the close price for all shares.
- dockerize the extractor and run it in k8s
- upload the result db to cos

2018-12-23
- create FEATURE table by feature_definition automatically.
